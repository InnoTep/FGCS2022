README

This dataset has been used in the paper:
[1] Rim Helaoui, Daniele Riboni, Heiner Stuckenschmidt, "A Probabilistic Ontological Framework for the Recognition of Multilevel Human Activities". In Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2013), pp. 345-354, ACM.

Activities at level 2 and 3 have been manually labeled by the authors of [1]. The original dataset was acquired within the Opportunity EU Project:
[2] Lukowicz, P. et al. Recording a complex, multi modal activity data set for context recognition 1st Workshop on Context-Systems Design, Evaluation and Optimisation at ARCS, 2010.

If you use the dataset, please cite [1] and [2].


The dataset includes three morning routines of 3 subjects each (S10, S11 and S12). For instance, S11-ADL3 refers to the third morning routine of S11.

Atomic Gestures (AG) are in the "Level-4" directory as text files. The first column represents the timestamp in milliseconds. The second represents the duration of AG in milliseconds. The third represents the mode of locomotion. The fifth (resp. sixth) represents the AG of the left (resp. right) arm.

Manipulative Gestures (MG, level 3), Simple Activities (SA, level 2), and Complex Activities (CA, level 1) are in directory "Levels-3-2-1". The first (resp. second) column represents the start (resp. end) timestamp of the activity; the third column represent the activity label.

For questions, contact Rim Helaoui (rim@informatik.uni-mannheim.de) and Daniele Riboni (daniele.riboni@unimi.it)
